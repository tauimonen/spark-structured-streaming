{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7418171f-8131-4ac6-879f-66a26057072e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import window, avg\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d068fba3-6396-4251-bf85-f08416f5063b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "source_path = \"/Volumes/streaming_demo/weather_stream/weather_stream_volume/source/live_weather\"\n",
    "\n",
    "schema_location = \"/Volumes/streaming_demo/weather_stream/weather_stream_volume/source/schemas/_live_weather_schema\"\n",
    "\n",
    "# Define schema explicitly because CSV files store timestamps as strings.\n",
    "# Without specifying TimestampType, Spark would read them as strings,\n",
    "# causing issues with time-based operations in streaming.\n",
    "schema = StructType([\n",
    "    StructField(\"event_id\", StringType()),\n",
    "    StructField(\"timestamp\", TimestampType()),\n",
    "    StructField(\"city\", StringType()),\n",
    "    StructField(\"temperature_c\", DoubleType()),\n",
    "    StructField(\"humidity_percent\", IntegerType()),\n",
    "    StructField(\"wind_speed_kmh\", DoubleType())\n",
    "])\n",
    "\n",
    "df = spark.readStream.\\\n",
    "    format(\"cloudFiles\").\\\n",
    "    option(\"cloudFiles.format\", \"csv\").\\\n",
    "    option(\"cloudFiles.schemaLocation\", schema_location).\\\n",
    "    schema(schema).\\\n",
    "    load(source_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "24d1f47c-ab7a-4440-a257-4cb5c196f201",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{\"window\":393},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1766062197593}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.withWatermark(\"timestamp\", \"30 seconds\").\\\n",
    "    groupBy(\n",
    "        window(\"timestamp\", \"60 seconds\"),\n",
    "        \"city\").\\\n",
    "    agg(\n",
    "        avg(\"temperature_c\"),\n",
    "        avg(\"humidity_percent\"),\n",
    "        avg(\"wind_speed_kmh\")\n",
    "        ).display()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Watermarking",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
